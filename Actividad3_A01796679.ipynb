{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c34PV_5Msn48",
        "dfMC8dJIs9pZ",
        "X8tNX9JHs963",
        "INuWYq21s-IH",
        "Uj8q83Nqs-TH"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## Curso: **Análisis de Grandes Volúmenes de Datos**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Profesor: Dr. Iván Olmos Pineda\n",
        "\n",
        "## Actividad Semana 6\n",
        "\n",
        "### **Aprendizaje supervisado y no supervisado**\n",
        "\n",
        "### A01796679"
      ],
      "metadata": {
        "id": "Q4ThY8Q5uarE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Introducción teórica**:\n"
      ],
      "metadata": {
        "id": "c34PV_5Msn48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El aprendizaje automático (Machine Learning) es una rama de la inteligencia artificial que permite a las computadoras aprender a partir de datos y tomar decisiones sin estar explícitamente programadas para cada tarea. En términos generales, los algoritmos de aprendizaje automático se clasifican en dos grandes grupos: aprendizaje supervisado y aprendizaje no supervisado.\n",
        "\n",
        " ## **Aprendizaje Supervisado**\n",
        "\n",
        "El aprendizaje supervisado se basa en el uso de un conjunto de datos etiquetado, donde cada observación incluye una serie de características (variables independientes) y una etiqueta o valor objetivo (variable dependiente). El objetivo es que el algoritmo aprenda una función que relacione las características con las etiquetas, para luego poder realizar predicciones sobre datos nuevos.\n",
        "\n",
        "Entre los algoritmos más representativos en la literatura se encuentran:\n",
        "\n",
        "- Regresión Lineal y Regresión Logística\n",
        "- Árboles de Decisión (Decision Trees)\n",
        "- Bosques Aleatorios (Random Forest)\n",
        "- Gradient Boosted Trees (GBTClassifier)\n",
        "- Redes Neuronales Multicapa (Multilayer Perceptron)\n",
        "- Máquinas de Vectores de Soporte (SVM)\n",
        "\n",
        "En el contexto de PySpark, una herramienta de procesamiento distribuido sobre Apache Spark, los algoritmos supervisados disponibles a través del módulo pyspark.ml (MLlib) incluyen:\n",
        "\n",
        "- DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\n",
        "- MultilayerPerceptronClassifier\n",
        "- LogisticRegression, LinearRegression\n",
        "- NaiveBayes\n",
        "\n",
        "\n",
        "## **Aprendizaje No Supervisado**\n",
        "\n",
        "En el aprendizaje no supervisado no se utilizan etiquetas; el objetivo es descubrir estructuras ocultas, patrones o agrupamientos en los datos. Es comúnmente utilizado en tareas como segmentación de clientes, reducción de dimensionalidad y análisis exploratorio.\n",
        "\n",
        "Algunos algoritmos representativos son:\n",
        "\n",
        "- K-Means\n",
        "- Gaussian Mixture Models\n",
        "- Clustering Jerárquico\n",
        "- Análisis de Componentes Principales (PCA)\n",
        "- Modelos de Tópicos como LDA\n",
        "\n",
        "En PySpark, se pueden aplicar varios algoritmos no supervisados a través de pyspark.ml.clustering y pyspark.ml.feature, entre ellos:\n",
        "\n",
        "- KMeans\n",
        "- GaussianMixture\n",
        "- PowerIterationClustering (PIC)\n",
        "- PCA (para reducción de dimensionalidad)\n",
        "- LDA (Latent Dirichlet Allocation, para modelado de temas)\n"
      ],
      "metadata": {
        "id": "51vRtwhNwRcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Selección de los datos**:\n",
        "\n"
      ],
      "metadata": {
        "id": "dfMC8dJIs9pZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se seleccionó el dataset \"Chicago Crimes - 2001 to Present\", el cual contiene información\n",
        "detallada sobre crímenes reportados en la ciudad de Chicago desde el año 2001 hasta la\n",
        "actualidad. Ahora bien, el volumen y la riqueza de atributos de este dataset permiten\n",
        "trabajar con un escenario real de Big Data, donde el procesamiento eficiente de grandes\n",
        "cantidades de información es fundamental. El **objetivo** de esta actividad es **aplicar algoritmos de aprendizaje supervisado y no supervisado mediante PySpark** para la resolución de problemas en análisis de datos, fomentando el desarrollo de habilidades prácticas en el manejo y procesamiento eficiente de grandes conjuntos de datos."
      ],
      "metadata": {
        "id": "l9NE9jyNyd7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#librerias\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.functions import col, when, isnan, count, udf,sum, isnull\n",
        "from pyspark.sql.types import IntegerType, DoubleType\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pyspark.sql.functions import to_timestamp, year, month, dayofweek\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TSpsI0ncya6v"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "lrmCgg2opME-"
      },
      "outputs": [],
      "source": [
        "# Detenemos cualquier sesión de Spark activa para evitar conflictos\n",
        "if SparkContext._active_spark_context:\n",
        "    SparkContext._active_spark_context.stop()\n",
        "\n",
        "# Iniciamos una nueva SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Police Crimes\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset contiene más de 8 millones de registros de incidentes criminales ocurridos en la\n",
        "ciudad de Chicago, recopilados por el Departamento de Policía. Cada registro describe un\n",
        "evento único, proporcionando múltiples atributos que facilitan un análisis profundo de la\n",
        "actividad delictiva."
      ],
      "metadata": {
        "id": "cQmHPt4f1Zgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el archivo CSV como DataFrame de Spark\n",
        "ruta = \"/content/Chicago_Crimes_-_2001_to_Present.csv\"\n",
        "df = spark.read.csv(ruta, header=True, inferSchema=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKT0P491qvLs",
        "outputId": "c7dc4604-4557-4ae7-b1fc-1522708ad3e8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+--------------------+--------------------+----+------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+\n",
            "|      ID|Case Number|                Date|               Block|IUCR|Primary Type|         Description|Location Description|Arrest|Domestic|Beat|District|Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|          Updated On|    Latitude|    Longitude|            Location|\n",
            "+--------+-----------+--------------------+--------------------+----+------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+\n",
            "|10224738|   HY411648|09/05/2015 01:30:...|     043XX S WOOD ST|0486|     BATTERY|DOMESTIC BATTERY ...|           RESIDENCE| false|    true| 924|       9|  12|            61|     08B|     1165074|     1875917|2015|02/10/2018 03:50:...|41.815117282|-87.669999562|(41.815117282, -8...|\n",
            "|10224739|   HY411615|09/04/2015 11:30:...| 008XX N CENTRAL AVE|0870|       THEFT|      POCKET-PICKING|             CTA BUS| false|   false|1511|      15|  29|            25|      06|     1138875|     1904869|2015|02/10/2018 03:50:...|41.895080471|-87.765400451|(41.895080471, -8...|\n",
            "|11646166|   JC213529|09/01/2018 12:01:...|082XX S INGLESIDE...|0810|       THEFT|           OVER $500|           RESIDENCE| false|    true| 631|       6|   8|            44|      06|        NULL|        NULL|2018|04/06/2019 04:04:...|        NULL|         NULL|                NULL|\n",
            "|10224740|   HY411595|09/05/2015 12:45:...|   035XX W BARRY AVE|2023|   NARCOTICS|POSS: HEROIN(BRN/...|            SIDEWALK|  true|   false|1412|      14|  35|            21|      18|     1152037|     1920384|2015|02/10/2018 03:50:...|41.937405765|-87.716649687|(41.937405765, -8...|\n",
            "|10224741|   HY411610|09/05/2015 01:00:...| 0000X N LARAMIE AVE|0560|     ASSAULT|              SIMPLE|           APARTMENT| false|    true|1522|      15|  28|            25|     08A|     1141706|     1900086|2015|02/10/2018 03:50:...|41.881903443|-87.755121152|(41.881903443, -8...|\n",
            "+--------+-----------+--------------------+--------------------+----+------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspeccionamos el esquema inferido automáticamente\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P59vMh00q3Cj",
        "outputId": "e15b1356-4b6f-48bd-ac32-132918927b86"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID: integer (nullable = true)\n",
            " |-- Case Number: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Block: string (nullable = true)\n",
            " |-- IUCR: string (nullable = true)\n",
            " |-- Primary Type: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Location Description: string (nullable = true)\n",
            " |-- Arrest: boolean (nullable = true)\n",
            " |-- Domestic: boolean (nullable = true)\n",
            " |-- Beat: integer (nullable = true)\n",
            " |-- District: integer (nullable = true)\n",
            " |-- Ward: integer (nullable = true)\n",
            " |-- Community Area: integer (nullable = true)\n",
            " |-- FBI Code: string (nullable = true)\n",
            " |-- X Coordinate: integer (nullable = true)\n",
            " |-- Y Coordinate: integer (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Updated On: string (nullable = true)\n",
            " |-- Latitude: double (nullable = true)\n",
            " |-- Longitude: double (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumen estadístico de todas las variables\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIHgs1g9q6SW",
        "outputId": "81747c54-99da-4eef-a759-cc0588b16c30"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+--------------------+--------------+------------------+-----------------+---------------+--------------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-------------------+--------------------+--------------------+\n",
            "|summary|                ID|       Case Number|                Date|         Block|              IUCR|     Primary Type|    Description|Location Description|              Beat|          District|              Ward|    Community Area|          FBI Code|     X Coordinate|      Y Coordinate|              Year|          Updated On|           Latitude|           Longitude|            Location|\n",
            "+-------+------------------+------------------+--------------------+--------------+------------------+-----------------+---------------+--------------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-------------------+--------------------+--------------------+\n",
            "|  count|           7811711|           7811707|             7811711|       7811711|           7811711|          7811711|        7811711|             7801153|           7811711|           7811664|           7196863|           7198235|           7811711|          7724246|           7724246|           7811711|             7811711|            7724246|             7724246|             7724246|\n",
            "|   mean|  7047235.09462818|314071.94444444444|                NULL|          NULL|1120.9696163074661|             NULL|           NULL|                NULL|1185.8247616943331|11.294905029197364| 22.75510913574428|  37.4813988429108|12.077565887306832|1164603.286751354|1885786.9657176894|2009.9892941507949|                NULL|  41.84219488113005|  -87.67148557998773|                NULL|\n",
            "| stddev|3514586.1451125084|  132968.524780014|                NULL|          NULL| 811.5586530819171|             NULL|           NULL|                NULL| 703.1754648166113| 6.953115491876338|13.850822546678101|21.541659607513346|  7.30851801814186|16840.02517325935|32267.013002939297| 6.296393348513412|                NULL|0.08877275492270253|0.061061439033470145|                NULL|\n",
            "|    min|               634|         .JB299184|01/01/2001 01:00:...|0000X E 100 PL|              0110|            ARSON| $300 AND UNDER|\"CTA \"\"L\"\" PLATFORM\"|               111|                 1|                 1|                 0|               01A|                0|                 0|              2001|01/01/2007 07:32:...|       36.619446395|       -91.686565684|(36.619446395, -9...|\n",
            "|    max|          13096706|         ZZZ199957|12/31/2022 12:59:...|   XX  UNKNOWN|              9901|WEAPONS VIOLATION|WIREROOM/SPORTS|                YMCA|              2535|                31|                50|                77|                26|          1205119|           1951622|              2023|12/31/2022 03:54:...|       42.022910333|       -87.524529378|(42.022910333, -8...|\n",
            "+-------+------------------+------------------+--------------------+--------------+------------------+-----------------+---------------+--------------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimiendo los tipos de datos del Dataframe\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60m6oKlTMnK8",
        "outputId": "1539e0ec-3f87-4836-b08e-66618e6176ab"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ID', 'int'),\n",
              " ('Case Number', 'string'),\n",
              " ('Date', 'string'),\n",
              " ('Block', 'string'),\n",
              " ('IUCR', 'string'),\n",
              " ('Primary Type', 'string'),\n",
              " ('Description', 'string'),\n",
              " ('Location Description', 'string'),\n",
              " ('Arrest', 'boolean'),\n",
              " ('Domestic', 'boolean'),\n",
              " ('Beat', 'int'),\n",
              " ('District', 'int'),\n",
              " ('Ward', 'int'),\n",
              " ('Community Area', 'int'),\n",
              " ('FBI Code', 'string'),\n",
              " ('X Coordinate', 'int'),\n",
              " ('Y Coordinate', 'int'),\n",
              " ('Year', 'int'),\n",
              " ('Updated On', 'string'),\n",
              " ('Latitude', 'double'),\n",
              " ('Longitude', 'double'),\n",
              " ('Location', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Número de registros: \" + str(df.count()))\n",
        "print(\"Número de columnas: \" + str(len(df.columns)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw3BqnDcQ6N9",
        "outputId": "0640a2cd-1443-428d-db0a-447487e95157"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de registros: 7811711\n",
            "Número de columnas: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la siguiente celda podemos observar que la mayoría de las columnas cuentan con datos\n",
        "completos o casi completos, lo cual es positivo para el análisis. Las columnas ´Ward´ y\n",
        "´Community Area’ presentan la mayor cantidad de valores nulos, con cerca de 7.8% de los\n",
        "registros afectados. También, las coordenadas geográficas(X, Y, Latitud, Longitud y\n",
        "Location) muestran un porcentaje ligeramente superior al 1% de datos faltantes. Será\n",
        "importante prestar atención a estos valores nulos durante la limpieza y el análisis futuro\n",
        "para evitar que impacten negativamente en los resultados, especialmente en estudios\n",
        "relacionados con segmentación geográfica o análisis por áreas administrativas."
      ],
      "metadata": {
        "id": "LbsCJLr41tcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos una expresión para cada columna para contar nulos\n",
        "null_counts = df.select([\n",
        "    sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns\n",
        "])\n",
        "\n",
        "null_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uxlyNG_q8Zu",
        "outputId": "9337b76b-7e02-42bc-ccf5-23fbaae4b911"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+------+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
            "| ID|Case Number|Date|Block|IUCR|Primary Type|Description|Location Description|Arrest|Domestic|Beat|District|  Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|Updated On|Latitude|Longitude|Location|\n",
            "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+------+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
            "|  0|          4|   0|    0|   0|           0|          0|               10558|     0|       0|   0|      47|614848|        613476|       0|       87465|       87465|   0|         0|   87465|    87465|   87465|\n",
            "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+------+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para garantizar que cada partición tenga una muestra representativa de los datos\n",
        "disponibles, se utilizará la técnica de muestreo aleatorio estratificado con fracción fija\n",
        "(fraction) en PySpark. Esta técnica asegura que dentro de cada subconjunto de datos se\n",
        "mantenga la proporción de ocurrencias, evitando sesgos por sobre o subrepresentación."
      ],
      "metadata": {
        "id": "l-0M8C960Wkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Chicago Crime Partitioning\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "ruta = \"/content/Chicago_Crimes_-_2001_to_Present.csv\"\n",
        "\n",
        "df = spark.read.csv(ruta, header=True, inferSchema=True)\n",
        "\n",
        "# Aplicamos reglas de particionamiento\n",
        "regla_A = df.filter((col(\"Primary Type\") == \"THEFT\") & (col(\"Domestic\") == True))\n",
        "regla_B = df.filter((col(\"Primary Type\") == \"BATTERY\") & (col(\"Domestic\") == False))\n",
        "regla_C = df.filter((col(\"Primary Type\") == \"NARCOTICS\") & (col(\"Domestic\") == True))\n",
        "regla_D = df.filter((col(\"Primary Type\") == \"ASSAULT\") & (col(\"Domestic\") == False))\n",
        "\n",
        "# Mostramos el tamaño de cada conjunto completo\n",
        "print(\"Tamaño total por regla:\")\n",
        "print(\"Regla A:\", regla_A.count())\n",
        "print(\"Regla B:\", regla_B.count())\n",
        "print(\"Regla C:\", regla_C.count())\n",
        "print(\"Regla D:\", regla_D.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6mkqSlkq_Vx",
        "outputId": "0f8d4c92-496b-4c89-f6a3-63d2f4d5990a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño total por regla:\n",
            "Regla A: 44739\n",
            "Regla B: 801552\n",
            "Regla C: 312\n",
            "Regla D: 392983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para garantizar que cada partición tenga una muestra representativa de los datos\n",
        "disponibles, se utilizará la técnica de muestreo aleatorio estratificado con fracción fija\n",
        "(fraction) en PySpark. Esta técnica asegura que dentro de cada subconjunto de datos se\n",
        "mantenga la proporción de ocurrencias, evitando sesgos por sobre o subrepresentación."
      ],
      "metadata": {
        "id": "U1mH4Xz26lwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraemos una muestra del 10% con semilla fija\n",
        "muestra_A = regla_A.sample(fraction=0.1, seed=42)\n",
        "muestra_B = regla_B.sample(fraction=0.1, seed=42)\n",
        "muestra_C = regla_C.sample(fraction=0.1, seed=42)\n",
        "muestra_D = regla_D.sample(fraction=0.1, seed=42)\n",
        "\n",
        "# Mostramos el tamaño de cada muestra\n",
        "print(\"\\nTamaño de la muestra por regla:\")\n",
        "print(\"Muestra A:\", muestra_A.count())\n",
        "print(\"Muestra B:\", muestra_B.count())\n",
        "print(\"Muestra C:\", muestra_C.count())\n",
        "print(\"Muestra D:\", muestra_D.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGdUGN9y6nDd",
        "outputId": "32c840bd-bc41-4385-92ef-815d6fb9148c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tamaño de la muestra por regla:\n",
            "Muestra A: 4391\n",
            "Muestra B: 80409\n",
            "Muestra C: 40\n",
            "Muestra D: 39349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Preparación de los datos**:\n",
        "En esta etapa, se deberán de aplicar estrategias de corrección sobre los datos que integran a la muestra M que se ha preparado en el paso previo, de tal forma que de deje un conjunto M listo para ser procesado por los algoritmos de aprendizaje a aplicar. Para ello se deben de considerar pasos como: corrección de registros / columnas con valores nulos, identificación de valores atípicos, transformación de los tipos de datos, etc. Con lo anterior, se tendrá una muestra M pre-procesada."
      ],
      "metadata": {
        "id": "X8tNX9JHs963"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unimos todas las muestras en un solo DataFrame\n",
        "muestra_unificada = muestra_A.union(muestra_B).union(muestra_C).union(muestra_D)\n",
        "\n",
        "# Verificamos valores nulos\n",
        "nulos = muestra_unificada.select([\n",
        "    sum(col(c).isNull().cast(\"int\")).alias(c) for c in muestra_unificada.columns\n",
        "])\n",
        "nulos.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJEL1ew2IuKN",
        "outputId": "cd477191-967c-4e16-acea-ab7f6cec0635"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+-----+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
            "| ID|Case Number|Date|Block|IUCR|Primary Type|Description|Location Description|Arrest|Domestic|Beat|District| Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|Updated On|Latitude|Longitude|Location|\n",
            "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+-----+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
            "|  0|          0|   0|    0|   0|           0|          0|                   0|     0|       0|   0|       1|10750|         10762|       0|         592|         592|   0|         0|     592|      592|     592|\n",
            "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+-----+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables de entrada y objetivo\n",
        "columnas_modelo = ['Primary Type', 'Domestic', 'District', 'Community Area', 'Arrest']  # 'Arrest' como variable objetivo\n",
        "\n",
        "# Filtramos columnas\n",
        "df_modelo = muestra_unificada.select(columnas_modelo)\n",
        "\n",
        "# Eliminamos filas con valores nulos en estas columnas\n",
        "df_modelo = df_modelo.dropna()"
      ],
      "metadata": {
        "id": "v2NmEhwMwZdZ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificamos 'Primary Type'\n",
        "indexador_tipo = StringIndexer(inputCol='Primary Type', outputCol='PrimaryTypeIndex')\n",
        "df_modelo = indexador_tipo.fit(df_modelo).transform(df_modelo)\n",
        "\n",
        "# Codificamos 'Arrest' (target)\n",
        "df_modelo = df_modelo.withColumn(\"Arrest_str\", col(\"Arrest\").cast(\"string\"))\n",
        "indexador_arresto = StringIndexer(inputCol='Arrest_str', outputCol='label')\n",
        "df_modelo = indexador_arresto.fit(df_modelo).transform(df_modelo)"
      ],
      "metadata": {
        "id": "HazLDZmPwepL"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensamblamos las características en una sola columna 'features'\n",
        "ensamblador = VectorAssembler(\n",
        "    inputCols=['PrimaryTypeIndex', 'Domestic', 'District', 'Community Area'],\n",
        "    outputCol='features'\n",
        ")\n",
        "df_final = ensamblador.transform(df_modelo).select('features', 'label')"
      ],
      "metadata": {
        "id": "9wPXoywlyL4d"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Preparación del conjunto de entrenamiento y prueba**:\n",
        "Para dividir la muestra `M` en conjuntos de entrenamiento y prueba, utilicé la función `randomSplit()` de PySpark con una proporción del 70% para entrenamiento y 30% para prueba, estableciendo una semilla fija (`seed=42`) para garantizar la reproducibilidad de los resultados.\n",
        "\n",
        "Elegí esta técnica de muestreo aleatorio simple porque, al haber construido previamente la muestra `M` mediante un muestreo estratificado sobre reglas bien definidas (combinando tipo de crimen y naturaleza doméstica del delito), puedo asegurar que ya se mantiene la representatividad dentro del conjunto total. El muestreo aleatorio posterior me permite evitar sesgos adicionales durante la asignación a los subconjuntos de entrenamiento y prueba.\n",
        "\n",
        "Decidí usar la proporción 70/30 porque es una práctica común en aprendizaje automático, ya que proporciona un buen equilibrio: por un lado, me asegura un conjunto de entrenamiento suficientemente grande como para que el modelo generalice adecuadamente, y por otro, me permite contar con un conjunto de prueba significativo para evaluar el desempeño del modelo de forma confiable.\n"
      ],
      "metadata": {
        "id": "INuWYq21s-IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df_final.randomSplit([0.7, 0.3], seed=42)\n",
        "print(\"Tamaño entrenamiento:\", train_data.count())\n",
        "print(\"Tamaño prueba:\", test_data.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKulFzKBynTq",
        "outputId": "fa333ad9-7d7b-4787-f626-96ac6b3e2fe0"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño entrenamiento: 79375\n",
            "Tamaño prueba: 34051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. **Construcción de modelos de aprendizaje supervisado y no supervisado**:\n",
        "Para este punto realizarás dos experimentos separados, dónde se aplicará un algoritmo de aprendizaje supervisado y uno de aprendizaje no supervisado sobre la muestra M. Para el caso de aprendizaje supervisado, se deberá de identificar cuál es la variable objetivo (columna) de aprendizaje, mientras que, para el caso de aprendizaje no supervisado, se debe de seleccionar todas las columnas que se desean considerar como características bajo las cuales se realizará el proceso de agrupamiento. Usando las implementaciones correspondientes de PySpark, se deberá de ejecutar el aprendizaje correspondiente a partir de la invocación de las funciones respectivas. Para este ejercicio, se deberá seleccionar un criterio básico para medir la calidad del resultado obtenido, dependiendo de cada tipo de aprendizaje implementado. La elección quedará a juicio de cada estudiante.\n"
      ],
      "metadata": {
        "id": "Uj8q83Nqs-TH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Algoritmo de aprendizaje Supervisado:"
      ],
      "metadata": {
        "id": "F_txXUdw0hDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definimos el modelo\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=100, seed=42)\n",
        "\n",
        "# Entrenamos el modelo con el conjunto de entrenamiento\n",
        "modelo_rf = rf.fit(train_data)\n",
        "\n",
        "# Aplicamos el modelo al conjunto de prueba\n",
        "predicciones = modelo_rf.transform(test_data)\n",
        "\n",
        "# Mostramos algunas predicciones\n",
        "predicciones.select(\"prediction\", \"label\", \"features\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQLIEbxkzhFn",
        "outputId": "ec8683fc-19ea-46b5-c6f2-89ae2fd0e2a5"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+------------------+\n",
            "|prediction|label|          features|\n",
            "+----------+-----+------------------+\n",
            "|       0.0|  0.0|[2.0,1.0,1.0,32.0]|\n",
            "|       0.0|  0.0|[2.0,1.0,1.0,35.0]|\n",
            "|       0.0|  0.0|[2.0,1.0,2.0,35.0]|\n",
            "|       0.0|  1.0|[2.0,1.0,2.0,35.0]|\n",
            "|       0.0|  0.0|[2.0,1.0,2.0,36.0]|\n",
            "+----------+-----+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluador usando precisión\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "precision = evaluator.evaluate(predicciones)\n",
        "\n",
        "# F1-score\n",
        "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1_score = f1_evaluator.evaluate(predicciones)\n",
        "\n",
        "print(f\"Precisión del modelo: {precision:.4f}\")\n",
        "print(f\"F1-score del modelo: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqjBNaaj06K9",
        "outputId": "a6232555-9752-469c-8aad-8e92a7a4cade"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.7881\n",
            "F1-score del modelo: 0.6950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación en el conjunto de entrenamiento\n",
        "train_predictions = modelo_rf.transform(train_data)\n",
        "\n",
        "train_accuracy = evaluator.evaluate(train_predictions)\n",
        "train_f1 = f1_evaluator.evaluate(train_predictions)\n",
        "\n",
        "print(f\"Precisión en entrenamiento: {train_accuracy:.4f}\")\n",
        "print(f\"F1-score en entrenamiento: {train_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nvTVHvv1_z-",
        "outputId": "ebf6b306-9c53-4ebc-fe0b-5143be1af929"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión en entrenamiento: 0.7860\n",
            "F1-score en entrenamiento: 0.6922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion: Mi modelo no presenta síntomas de sobreentrenamiento ni subentrenamiento. Los valores de precisión y F1 son muy similares entre los conjuntos de entrenamiento y prueba, con diferencias menores al 1%, lo que indica que el modelo generaliza correctamente sin sobreajustarse ni fallar en captar patrones relevantes."
      ],
      "metadata": {
        "id": "Z0mTw8DB29i1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Algoritmo de aprendizaje no Supervisado"
      ],
      "metadata": {
        "id": "Tbyhblyj3a1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selección de variables para clustering\n",
        "columnas_clustering = ['PrimaryTypeIndex', 'Domestic', 'District', 'Community Area']\n",
        "\n",
        "# Ensamblamos características\n",
        "ensamblador_kmeans = VectorAssembler(inputCols=columnas_clustering, outputCol='features')\n",
        "df_kmeans = ensamblador_kmeans.transform(df_modelo).select('features')"
      ],
      "metadata": {
        "id": "p60YD7ks3Z-m"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos y entrenamos el modelo\n",
        "kmeans = KMeans(k=4, seed=42)\n",
        "modelo_kmeans = kmeans.fit(df_kmeans)\n",
        "\n",
        "# Aplicamos el modelo\n",
        "predicciones_kmeans = modelo_kmeans.transform(df_kmeans)"
      ],
      "metadata": {
        "id": "_-8Qrvhg3oRd"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación usando el índice de silueta (Silhouette Score)\n",
        "evaluator = ClusteringEvaluator(predictionCol='prediction', featuresCol='features', metricName='silhouette')\n",
        "silhouette = evaluator.evaluate(predicciones_kmeans)\n"
      ],
      "metadata": {
        "id": "bMk1jDJY3x8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Índice de silueta: {silhouette:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0huZoWDB7DKK",
        "outputId": "e5fb2504-2729-40e4-b1e1-63e81a949208"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Índice de silueta: 0.7554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusión:\n",
        "\n",
        "Entrené un modelo de agrupamiento K-Means utilizando las variables codificadas: tipo de crimen, si fue doméstico, distrito y área comunitaria. Seleccioné inicialmente 4 clústeres para explorar la estructura oculta en los datos.\n",
        "\n",
        "El modelo logró un **índice de silueta de 0.7554**, lo cual indica que los clústeres generados están bien definidos y presentan una buena separación entre sí. Este valor sugiere que el modelo fue capaz de identificar patrones latentes significativos en los datos, agrupando registros con características similares de manera efectiva.\n",
        "\n",
        "Este resultado me parece bastante positivo, considerando la naturaleza compleja y multidimensional del fenómeno criminal. Para refinar aún más el análisis, podría experimentar con distintos valores de `k` y observar cómo varía el índice de silueta para elegir el número óptimo de clústeres.\n"
      ],
      "metadata": {
        "id": "_O76dCHc7K1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. FINAL"
      ],
      "metadata": {
        "id": "bjg51bpoG9Za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparación entre los modelos supervisado y no supervisado**\n",
        "\n",
        "Después de aplicar ambos enfoques de aprendizaje, considero que el modelo **supervisado (Random Forest)** y el **no supervisado (K-Means)** ofrecieron perspectivas complementarias sobre los datos.\n",
        "\n",
        "El modelo **supervisado** alcanzó una **precisión del 78.81%** y un **F1-score de 69.50%**, lo cual indica un buen desempeño al predecir si se realizó un arresto en función de variables como tipo de crimen, distrito, domesticidad y área comunitaria. Además, la similitud entre los resultados de entrenamiento y prueba sugiere que el modelo generaliza bien y no presenta sobreajuste.\n",
        "\n",
        "Por otro lado, el modelo **no supervisado (K-Means)** logró un **índice de silueta de 0.7554**, lo que indica que los clústeres están bien definidos. Este resultado es bastante sólido en términos de agrupamiento, lo que demuestra que el modelo fue capaz de identificar patrones latentes y agrupaciones significativas en los datos sin necesidad de etiquetas.\n",
        "\n",
        "En resumen, considero que **ambos modelos fueron exitosos en sus respectivos objetivos**, pero si tuviera que elegir uno por su **impacto práctico**, me inclinaría por el **modelo supervisado**. Esto se debe a que permite una interpretación directa y útil para decisiones reales, como la predicción de arrestos. Sin embargo, el análisis no supervisado también aportó valor al revelar segmentaciones útiles dentro del conjunto de datos.\n"
      ],
      "metadata": {
        "id": "JmxG09qaG0eb"
      }
    }
  ]
}