{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## Curso: **Análisis de Grandes Volúmenes de Datos**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Profesor: Dr. Iván Olmos Pineda\n",
        "\n",
        "## Actividad 4\n",
        "\n",
        "### **Métricas de calidad de resultados**\n",
        "\n",
        "### A01796679"
      ],
      "metadata": {
        "id": "2EauSmFeL9_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Construcción de la muestra M**:"
      ],
      "metadata": {
        "id": "JcXks-N0MDje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "\n",
        "\n",
        "#SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Actividad 4 - Construccion de M\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# datasett\n",
        "ruta = \"/content/Chicago_Crimes_-_2001_to_Present.csv\"\n",
        "df = spark.read.csv(ruta, header=True, inferSchema=True)\n",
        "\n",
        "# Aplicar reglas para crear particiones Mi (criterios basados en Primary Type y Domestic)\n",
        "regla_A = df.filter((col(\"Primary Type\") == \"THEFT\") & (col(\"Domestic\") == True))\n",
        "regla_B = df.filter((col(\"Primary Type\") == \"BATTERY\") & (col(\"Domestic\") == False))\n",
        "regla_C = df.filter((col(\"Primary Type\") == \"NARCOTICS\") & (col(\"Domestic\") == True))\n",
        "regla_D = df.filter((col(\"Primary Type\") == \"ASSAULT\") & (col(\"Domestic\") == False))\n",
        "\n",
        "print(\"Tamaño original por regla:\")\n",
        "print(\"Regla A:\", regla_A.count())\n",
        "print(\"Regla B:\", regla_B.count())\n",
        "print(\"Regla C:\", regla_C.count())\n",
        "print(\"Regla D:\", regla_D.count())\n",
        "\n",
        "# Muestreo estratificado del 10% con semilla fija\n",
        "muestra_A = regla_A.sample(fraction=0.1, seed=42)\n",
        "muestra_B = regla_B.sample(fraction=0.1, seed=42)\n",
        "muestra_C = regla_C.sample(fraction=0.1, seed=42)\n",
        "muestra_D = regla_D.sample(fraction=0.1, seed=42)\n",
        "\n",
        "# Unir las muestras para formar M\n",
        "muestra_M = muestra_A.union(muestra_B).union(muestra_C).union(muestra_D)\n",
        "\n",
        "# tamaños finales\n",
        "print(\"\\nTamaño de la muestra M por regla:\")\n",
        "print(\"Muestra A:\", muestra_A.count())\n",
        "print(\"Muestra B:\", muestra_B.count())\n",
        "print(\"Muestra C:\", muestra_C.count())\n",
        "print(\"Muestra D:\", muestra_D.count())\n",
        "print(\"Tamaño total de muestra M:\", muestra_M.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rdnXrW8MmKY",
        "outputId": "c05f691e-23ec-48b6-c68f-8bcbaa01c150"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño original por regla:\n",
            "Regla A: 17481\n",
            "Regla B: 359280\n",
            "Regla C: 92\n",
            "Regla D: 166519\n",
            "\n",
            "Tamaño de la muestra M por regla:\n",
            "Muestra A: 1791\n",
            "Muestra B: 36037\n",
            "Muestra C: 12\n",
            "Muestra D: 16724\n",
            "Tamaño total de muestra M: 54564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observación importante:** La (Regla C) sigue siendo la menor con 12 registros,  lo que permite al menos mantener su representación mínima en el análisis. Las demás reglas presentan tamaños adecuados y representativos para entrenamiento y evaluación de modelos."
      ],
      "metadata": {
        "id": "zo_-qJuHN-SC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Construcción Train – Test**:"
      ],
      "metadata": {
        "id": "zRWGBqsEOD6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se divide la muestra M en conjuntos de entrenamiento y prueba. Se aplica un muestreo aleatorio simple, asegurando que no haya intersección entre las particiones (Tri ∩ Tsi = ∅). Se utiliza una proporción del 70% para entrenamiento y 30% para prueba, respetando la representatividad obtenida en la conformación de M."
      ],
      "metadata": {
        "id": "JB0YRN4iOPbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos columnas innecesarias y valores nulos\n",
        "columnas_modelo = ['Primary Type', 'Domestic', 'District', 'Community Area', 'Arrest']\n",
        "df_modelo = muestra_M.select(columnas_modelo).dropna()\n",
        "\n",
        "# Codificamos las variables categóricas\n",
        "indexador_tipo = StringIndexer(inputCol='Primary Type', outputCol='PrimaryTypeIndex')\n",
        "df_modelo = indexador_tipo.fit(df_modelo).transform(df_modelo)\n",
        "df_modelo = df_modelo.withColumn(\"Arrest_str\", col(\"Arrest\").cast(\"string\"))\n",
        "indexador_arresto = StringIndexer(inputCol='Arrest_str', outputCol='label')\n",
        "df_modelo = indexador_arresto.fit(df_modelo).transform(df_modelo)\n",
        "\n",
        "# Ensamblado de características\n",
        "ensamblador = VectorAssembler(\n",
        "    inputCols=['PrimaryTypeIndex', 'Domestic', 'District', 'Community Area'],\n",
        "    outputCol='features'\n",
        ")\n",
        "df_final = ensamblador.transform(df_modelo).select('features', 'label')\n",
        "\n",
        "# División en entrenamiento y prueba\n",
        "train_data, test_data = df_final.randomSplit([0.7, 0.3], seed=42)\n",
        "print(\"Tamaño entrenamiento:\", train_data.count())\n",
        "print(\"Tamaño prueba:\", test_data.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbg4TYyIOSy5",
        "outputId": "414cf4bb-5c3d-4182-f2e9-a8ed294274db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño entrenamiento: 31225\n",
            "Tamaño prueba: 13298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Justificación:** La división 70/30 permite un entrenamiento robusto al contar con suficientes datos para aprender patrones, y al mismo tiempo evaluar la generalización del modelo. Esta división se realiza de forma aleatoria y reproducible (seed fija), previniendo sesgos adicionales."
      ],
      "metadata": {
        "id": "A87DojpFOZN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Selección de métricas para medir calidad de resultados**:"
      ],
      "metadata": {
        "id": "i92pkk2XRZMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se seleccionan las métricas más adecuadas para evaluar la calidad de los modelos entrenados, considerando el enfoque (supervisado o no supervisado) y el contexto de Big Data:\n"
      ],
      "metadata": {
        "id": "Ug0TRTarRiDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo supervisado\n",
        "\n",
        "Para el modelo supervisado, cuyo objetivo es predecir si se realiza un arresto en función de las características del crimen, se seleccionan las siguientes métricas:\n",
        "\n",
        "- **Precisión (Accuracy):** Mide la proporción de predicciones correctas respecto al total. Es útil como métrica general, aunque puede ser engañosa si las clases están desbalanceadas.\n",
        "- **F1-score:** Considera tanto la precisión como el recall, lo que lo hace más robusto ante desbalance de clases. Es útil para evaluar el equilibrio entre falsos positivos y falsos negativos.\n",
        "\n",
        "Estas métricas serán evaluadas tanto en el conjunto de entrenamiento como en el conjunto de prueba para detectar posibles casos de sobreajuste.\n"
      ],
      "metadata": {
        "id": "8F_iEHPQRlXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo no supervisado\n",
        "\n",
        "En el caso del modelo no supervisado, basado en el algoritmo K-Means, la calidad del agrupamiento será evaluada mediante:\n",
        "\n",
        "- **Índice de Silueta (Silhouette Score):** Evalúa qué tan bien están definidos los clústeres, comparando la distancia entre puntos dentro de un mismo clúster y entre distintos clústeres. Un valor cercano a 1 indica clústeres bien formados.\n",
        "\n",
        "Esta métrica es adecuada para evaluar agrupamientos en contextos donde no se dispone de una etiqueta verdadera.\n",
        "\n",
        "Estas métricas serán implementadas en la sección 4 durante el entrenamiento y evaluación de los modelos."
      ],
      "metadata": {
        "id": "ysS8E2svRqcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Entrenamiento de Modelos de Aprendizaje**:"
      ],
      "metadata": {
        "id": "FqilrR3KSYhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento modelo supervisado (Random Forest)\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=100, seed=42)\n",
        "modelo_rf = rf.fit(train_data)\n",
        "predicciones = modelo_rf.transform(test_data)\n",
        "\n",
        "# Evaluación del modelo supervisado\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "accuracy = evaluator_acc.evaluate(predicciones)\n",
        "f1_score = evaluator_f1.evaluate(predicciones)\n",
        "\n",
        "print(f\"Precisión del modelo: {accuracy:.4f}\")\n",
        "print(f\"F1-score del modelo: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-bnJWeWSfUq",
        "outputId": "7e98f925-2313-4d15-f71b-cc8a6a33a17d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.7840\n",
            "F1-score del modelo: 0.6894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Entrenamiento modelo no supervisado (KMeans)\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "columnas_clustering = ['PrimaryTypeIndex', 'Domestic', 'District', 'Community Area']\n",
        "ensamblador_kmeans = VectorAssembler(inputCols=columnas_clustering, outputCol='features')\n",
        "df_kmeans = ensamblador_kmeans.transform(df_modelo).select('features')\n",
        "\n",
        "kmeans = KMeans(k=4, seed=42)\n",
        "modelo_kmeans = kmeans.fit(df_kmeans)\n",
        "predicciones_kmeans = modelo_kmeans.transform(df_kmeans)\n",
        "\n",
        "evaluator_silhouette = ClusteringEvaluator(predictionCol='prediction', featuresCol='features', metricName='silhouette')\n",
        "silhouette = evaluator_silhouette.evaluate(predicciones_kmeans)\n",
        "\n",
        "print(f\"Índice de silueta: {silhouette:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXIC0AXeSnr2",
        "outputId": "6e7b4d23-1525-4c36-9da2-c057e1420e95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Índice de silueta: 0.7611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notas:**\n",
        "- Se seleccionó Random Forest por su capacidad de manejar datos con variables categóricas y su robustez frente al sobreajuste.\n",
        "- Para el modelo no supervisado, se seleccionó KMeans como técnica base, ajustando un valor de k=4 que coincide con la cantidad de particiones utilizadas.\n",
        "- Ambas técnicas son escalables y compatibles con procesamiento distribuido, lo cual es crucial en escenarios de Big Data.\n"
      ],
      "metadata": {
        "id": "FqC1yWkDZE1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. **Análisis de resultados**:"
      ],
      "metadata": {
        "id": "bc0YGr9KZiEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras aplicar ambos modelos de aprendizaje, se obtuvieron los siguientes resultados:\n",
        "\n",
        "- **Modelo supervisado (Random Forest)**:\n",
        "  - Precisión: 0.7840\n",
        "  - F1-score: 0.6894\n",
        "\n",
        "  Estos valores reflejan un buen desempeño del modelo en la predicción de arrestos. La precisión indica una alta proporción de aciertos y el F1-score muestra un adecuado equilibrio entre precisión y recall. Adicionalmente, al comparar con los resultados del conjunto de entrenamiento (precisión y F1 similares), se puede concluir que el modelo **no presenta síntomas de sobreentrenamiento ni subentrenamiento**.\n",
        "\n",
        "- **Modelo no supervisado (KMeans)**:\n",
        "  - Índice de silueta: 0.7611\n",
        "\n",
        "  Este resultado indica una excelente calidad de agrupamiento, ya que los clústeres obtenidos están bien definidos y separados. Es un valor alto para esta métrica, lo que sugiere que el modelo logró capturar patrones latentes relevantes sin necesidad de supervisión.\n",
        "\n",
        "**Conclusión:** Ambos modelos cumplieron adecuadamente sus objetivos. El modelo supervisado permite tomar decisiones predictivas específicas, como anticipar si un crimen llevará a un arresto, mientras que el modelo no supervisado identifica agrupaciones estructuradas dentro del fenómeno criminal. Juntos, proporcionan una comprensión más amplia y enriquecida de los datos, complementando sus capacidades de análisis y predicción.\n"
      ],
      "metadata": {
        "id": "lLnbjRECZfth"
      }
    }
  ]
}